root_path = '/home/dy/Flat-Lattice-Transformer/'


yangjie_rich_pretrain_unigram_path = '/home/dy/Flat-Lattice-Transformer/data/pretrain/gigaword_chn.all.a2b.uni.ite50.vec'
yangjie_rich_pretrain_bigram_path = '/home/dy/Flat-Lattice-Transformer/data/pretrain/gigaword_chn.all.a2b.bi.ite50.vec'
yangjie_rich_pretrain_word_path = '/home/dy/Flat-Lattice-Transformer/data/pretrain/ctb.50d.vec'
yangjie_rich_pretrain_char_and_word_path = '/home/dy/Flat-Lattice-Transformer/data/pretrain/yangjie_word_char_mix.txt'

lk_word_path_2 = '/home/dy/Flat-Lattice-Transformer/data/pretrain/sgns.merge.word'



# ontonote4ner_cn_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/OntoNote4NER'
# msra_ner_cn_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/MSRANER'
# resume_ner_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/ResumeNER'
weibo_ner_path = '/home/dy/Flat-Lattice-Transformer/data/'
aicup_ner_path = '/home/dy/aicup/data'

# # this path is for the output of preprocessing
# yangjie_rich_pretrain_char_and_word_path = '{}/yangjie_word_char_mix.txt'
#
#
#
# ontonote4ner_cn_path = '{}/OntoNote4NER'
# msra_ner_cn_path = '{}/MSRANER'
# resume_ner_path = '{}/ResumeNER'
# weibo_ner_path = '{}/WeiboNER'